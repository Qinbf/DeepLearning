{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更多课程请关注：http://edu.51cto.com/lecturer/index/user_id-12330098.html<br>\n",
    "QQ群：616043628<br>\n",
    "微信公众号：深度学习与神经网络<br>\n",
    "<img src=\"http://mp.weixin.qq.com/mp/qrcode?scene=10000004&size=102&__biz=MzIxMDQ3NzQ0Ng==\"\n",
    "style=\"width:150px;height:150px;float:left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import  metrics,linear_model\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "digits = load_digits()#载入数据\n",
    "X = digits.data#数据\n",
    "Y = digits.target#标签\n",
    "#输入数据归一化\n",
    "X -= X.min()\n",
    "X /= X.max()\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,test_size=0.2,random_state=0)\n",
    "\n",
    "\n",
    "#创建RBM模型\n",
    "logistic = linear_model.LogisticRegression()\n",
    "rbm = BernoulliRBM(random_state=0, verbose=True)\n",
    "classifier = Pipeline(steps=[('rbm', rbm), ('logistic', logistic)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -29.71, time = 0.08s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -29.74, time = 0.09s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -26.65, time = 0.09s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -25.49, time = 0.10s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -26.57, time = 0.09s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -23.67, time = 0.08s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -23.18, time = 0.10s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -23.40, time = 0.09s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -22.79, time = 0.08s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -23.69, time = 0.10s\n",
      "[BernoulliRBM] Iteration 11, pseudo-likelihood = -22.58, time = 0.09s\n",
      "[BernoulliRBM] Iteration 12, pseudo-likelihood = -22.52, time = 0.09s\n",
      "[BernoulliRBM] Iteration 13, pseudo-likelihood = -22.76, time = 0.10s\n",
      "[BernoulliRBM] Iteration 14, pseudo-likelihood = -21.99, time = 0.09s\n",
      "[BernoulliRBM] Iteration 15, pseudo-likelihood = -22.88, time = 0.09s\n",
      "[BernoulliRBM] Iteration 16, pseudo-likelihood = -21.64, time = 0.09s\n",
      "[BernoulliRBM] Iteration 17, pseudo-likelihood = -22.01, time = 0.08s\n",
      "[BernoulliRBM] Iteration 18, pseudo-likelihood = -21.53, time = 0.08s\n",
      "[BernoulliRBM] Iteration 19, pseudo-likelihood = -21.02, time = 0.09s\n",
      "[BernoulliRBM] Iteration 20, pseudo-likelihood = -21.63, time = 0.09s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('rbm', BernoulliRBM(batch_size=10, learning_rate=0.06, n_components=200, n_iter=20,\n",
       "       random_state=0, verbose=True)), ('logistic', LogisticRegression(C=6000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#设置学习率\n",
    "rbm.learning_rate = 0.06\n",
    "#设置迭代次数\n",
    "rbm.n_iter = 20\n",
    "#设置隐藏层单元\n",
    "rbm.n_components = 200\n",
    "logistic.C = 6000.0\n",
    "#训练模型\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic regression using RBM features:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        27\n",
      "          1       1.00      0.94      0.97        35\n",
      "          2       1.00      0.94      0.97        36\n",
      "          3       0.88      1.00      0.94        29\n",
      "          4       0.97      0.97      0.97        30\n",
      "          5       0.97      0.97      0.97        40\n",
      "          6       1.00      1.00      1.00        44\n",
      "          7       0.90      0.97      0.94        39\n",
      "          8       1.00      0.97      0.99        39\n",
      "          9       0.95      0.90      0.92        41\n",
      "\n",
      "avg / total       0.97      0.97      0.97       360\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(\"Logistic regression using RBM features:\\n%s\\n\" % (\n",
    "    metrics.classification_report(\n",
    "        Y_test,\n",
    "        classifier.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
